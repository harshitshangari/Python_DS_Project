{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from nose.tools import *\n",
    "import time\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV,cross_val_score \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ext_data = pd.read_csv(Path(\"Ext_Data\") / \"external_data_no_cyc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_parquet(Path(\"data\") / \"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ext_data = fin_ext_data.drop(['Unnamed: 0'], axis=1)\n",
    "fin_ext_data['date'] = pd.to_datetime(fin_ext_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = data.merge(fin_ext_data, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged = data1.merge(fin_ext_data, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = train_merged.sort_values([\"date\", \"counter_name\"])\n",
    "y_train = data_tr[\"log_bike_count\"].values\n",
    "X_train = data_tr.drop([\"log_bike_count\", \"bike_count\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ts = test_merged.sort_values([\"date\", \"counter_name\"])\n",
    "y_test = data_ts[\"log_bike_count\"].values\n",
    "X_test = data_ts.drop([\"log_bike_count\", \"bike_count\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Finally we can drop the original columns from the dataframe\n",
    "    return X.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "num_features = ['temp', 'dwpt', 'rhum', 'prcp', 'wdir', 'wspd', 'pres']\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\", \"season\"]\n",
    "\n",
    "rest_cols = ['holiday', 'weekend', 'is_night', 'lockdown1', 'lockdown2']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "        (\"numf\", StandardScaler(), num_features),\n",
    "        (\"rem\", 'passthrough', rest_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "params = {\"lgbmregressor__learning_rate\" : [0.01, 0.05, 0.1, 0.2],\n",
    "          \"lgbmregressor__max_depth\" : [5, 6, 8, 9, 10, 12],\n",
    "          \"lgbmregressor__num_leaves\" : [50, 100, 200, 400, 800, 1000],\n",
    "          \"lgbmregressor__min_data_in_leaf\" : [50, 100, 200, 500],\n",
    "          \"lgbmregressor__lambda_l2\": [1, 3, 5, 7, 9],\n",
    "          \"lgbmregressor__n_estimators\" : [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "regressor = LGBMRegressor()\n",
    "pipe = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "rscv = RandomizedSearchCV(pipe, param_distributions=params, n_iter=40, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=5, verbose=3)\n",
    "rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = rscv.best_params_\n",
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, rscv.predict(X_train), squared=False):.7f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set, RMSE={mean_squared_error(y_test, rscv.predict(X_test), squared=False):.7f}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train set r2, RMSE={r2_score(y_train, rscv.predict(X_train)):.7f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set r2, RMSE={r2_score(y_test, rscv.predict(X_test)):.7f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
